{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "seg_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7397, 500), (7397, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = None\n",
    "y = None\n",
    "\n",
    "db1_pos = ['chfdb']\n",
    "db1_neg = ['nsrdb', 'fantasia']\n",
    "db2_pos = ['chf2db']\n",
    "db2_neg = ['nsr2db']\n",
    "\n",
    "for db in db1_pos:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.ones(n_segments), np.zeros(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "for db in db1_neg:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.zeros(n_segments), np.ones(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5991, 500), (666, 500), (740, 500))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.scale(X, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=410)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=410)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 496, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 492, 16)           1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 246, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 246, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 244, 32)           1568      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 242, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 119, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 117, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 58, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 58, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 56, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 54, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 254,706\n",
      "Trainable params: 254,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 5s 97ms/step - loss: 0.5310 - acc: 0.7228 - val_loss: 0.3831 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85285, saving model to baseline_cnn.h5\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.3411 - acc: 0.8660 - val_loss: 0.3193 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85285 to 0.88138, saving model to baseline_cnn.h5\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 0.3046 - acc: 0.8807 - val_loss: 0.3055 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.88138\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 5s 98ms/step - loss: 0.2757 - acc: 0.8907 - val_loss: 0.2894 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.88138 to 0.88889, saving model to baseline_cnn.h5\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 5s 101ms/step - loss: 0.2646 - acc: 0.9034 - val_loss: 0.2730 - val_acc: 0.9129\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.88889 to 0.91291, saving model to baseline_cnn.h5\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 5s 99ms/step - loss: 0.2235 - acc: 0.9217 - val_loss: 0.2380 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.91291\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 5s 100ms/step - loss: 0.1997 - acc: 0.9287 - val_loss: 0.2134 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91291 to 0.91592, saving model to baseline_cnn.h5\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 5s 101ms/step - loss: 0.1869 - acc: 0.9322 - val_loss: 0.1991 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91592 to 0.92042, saving model to baseline_cnn.h5\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 5s 103ms/step - loss: 0.1761 - acc: 0.9354 - val_loss: 0.2032 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92042 to 0.92342, saving model to baseline_cnn.h5\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 5s 96ms/step - loss: 0.1690 - acc: 0.9372 - val_loss: 0.1790 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.92342 to 0.92943, saving model to baseline_cnn.h5\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 0.1597 - acc: 0.9392 - val_loss: 0.1754 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92943\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 5s 97ms/step - loss: 0.1481 - acc: 0.9466 - val_loss: 0.1756 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.92943\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 5s 98ms/step - loss: 0.1640 - acc: 0.9357 - val_loss: 0.1842 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92943\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 0.1326 - acc: 0.9529 - val_loss: 0.1804 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92943\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 0.1296 - acc: 0.9511 - val_loss: 0.1776 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92943 to 0.93093, saving model to baseline_cnn.h5\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 4s 95ms/step - loss: 0.1279 - acc: 0.9509 - val_loss: 0.1685 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.93093 to 0.93393, saving model to baseline_cnn.h5\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.1218 - acc: 0.9553 - val_loss: 0.1839 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93393\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 0.1235 - acc: 0.9548 - val_loss: 0.1676 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.93393 to 0.93544, saving model to baseline_cnn.h5\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 5s 96ms/step - loss: 0.1240 - acc: 0.9556 - val_loss: 0.1683 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93544\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1172 - acc: 0.9556 - val_loss: 0.1717 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93544\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.1210 - acc: 0.9529 - val_loss: 0.1751 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93544\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 4s 86ms/step - loss: 0.1161 - acc: 0.9554 - val_loss: 0.1716 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93544\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.1159 - acc: 0.9573 - val_loss: 0.1727 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93544\n",
      "Epoch 00023: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def get_model():\n",
    "    nclass = 2\n",
    "    inp = tf.keras.layers.Input(shape=(500, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"baseline_cnn.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid),\n",
    "          batch_size=128, epochs=100, callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695550351288056\n",
      "0.92\n",
      "0.9337837837837838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cnn_model = model\n",
    "\n",
    "pred_test_cnn = cnn_model.predict(X_test)\n",
    "pred_test_cnn = np.argmax(pred_test_cnn, axis=1)\n",
    "\n",
    "print(recall_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(precision_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(accuracy_score(y_test.argmax(axis=1), pred_test_cnn ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project5100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
