{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "seg_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7397, 500), (7397, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = None\n",
    "# y = None\n",
    "\n",
    "# for db in [\"chf2db\", \"chfdb\"]:\n",
    "#     for record in os.listdir(f'data/{db}/rr'):\n",
    "#         rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "#         n_segments = rr.shape[0] // seg_length\n",
    "#         rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "#         labels = np.c_[np.ones(n_segments), np.zeros(n_segments)]\n",
    "\n",
    "#         if x is None or y is None:\n",
    "#             x = rr\n",
    "#             y = labels\n",
    "#         else:\n",
    "#             x = np.r_[rr, x]\n",
    "#             y = np.r_[labels, y]\n",
    "\n",
    "\n",
    "# for db in [\"nsrdb\", \"nsr2db\", \"fantasia\"]:\n",
    "#     for record in os.listdir(f'data/{db}/rr'):\n",
    "#         rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "#         n_segments = rr.shape[0] // seg_length\n",
    "#         rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "#         labels = np.c_[np.zeros(n_segments), np.ones(n_segments)]\n",
    "\n",
    "#         if x is None or y is None:\n",
    "#             x = rr\n",
    "#             y = labels\n",
    "#         else:\n",
    "#             x = np.r_[rr, x]\n",
    "#             y = np.r_[labels, y]\n",
    "\n",
    "# x.shape, y.shape\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "db1_pos = ['chfdb']\n",
    "db1_neg = ['nsrdb', 'fantasia']\n",
    "db2_pos = ['chf2db']\n",
    "db2_neg = ['nsr2db']\n",
    "\n",
    "for db in db1_pos:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.ones(n_segments), np.zeros(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "for db in db1_neg:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.zeros(n_segments), np.ones(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5991, 500), (666, 500), (740, 500))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # from sklearn.model_selection import train_test_split\n",
    "# # from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# # x = preprocessing.scale(x, axis=1)\n",
    "# # # scaler = preprocessing.StandardScaler().fit_transform(x)\n",
    "\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=410)\n",
    "# # X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=410)\n",
    "\n",
    "# # X_train.shape, X_valid.shape, X_test.shape\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# X = preprocessing.scale(X, axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=410)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=410)\n",
    "\n",
    "# X_train.shape, X_valid.shape, X_test.shape\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    " \n",
    "# normalize?\n",
    "# X = (X - X.mean()) / X.std()\n",
    "X_raw = X.copy()\n",
    "X = preprocessing.scale(X, axis=1)\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=410)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=410)\n",
    " \n",
    " \n",
    "_, X_test_raw, _, y_test_raw = train_test_split(\n",
    "    X_raw, y, test_size=0.1, random_state=410)\n",
    " \n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_valid = scaler.transform(X_valid)\n",
    "# X_test = scaler.transform(X_test)\n",
    " \n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(y_train[:,0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input(shape=(500, 1))\n",
    "\n",
    "# def inception_lstm(inputs):\n",
    "#     a = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5, return_sequences=True))(inputs)\n",
    "#     a = tf.keras.layers.LSTM(5, return_sequences=True)(a)\n",
    "\n",
    "#     b = tf.keras.layers.Conv1D(5, kernel_size=1)(inputs)\n",
    "#     b = tf.keras.layers.Conv1D(5, kernel_size=3)(b)\n",
    "\n",
    "#     c = tf.keras.layers.Conv1D(5, kernel_size=1)(inputs)\n",
    "#     c = tf.keras.layers.Conv1D(5, kernel_size=5)(c)\n",
    "\n",
    "#     d = tf.keras.layers.MaxPool1D(3)(inputs)\n",
    "#     d = tf.keras.layers.Conv1D(5, kernel_size=1)(d)\n",
    "\n",
    "#     concat = tf.keras.layers.Concatenate(1)([a, b, c, d])\n",
    "#     return concat\n",
    "\n",
    "# layer1 = inception_lstm(inputs)\n",
    "# layer2 = inception_lstm(layer1)\n",
    "# dropout = tf.keras.layers.Dropout(0.2)(layer2)\n",
    "# flattened = tf.keras.layers.Flatten()(dropout)\n",
    "# output = tf.keras.layers.Dense(2, activation='sigmoid')(flattened)\n",
    "\n",
    "# model = tf.keras.Model(inputs, output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=loss_fn,\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "# model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid),\n",
    "#           batch_size=128, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model_lstm.keras')\n",
    "# lstm_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# y_pred_lstm = lstm_model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(recall_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "# print(precision_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "# print(accuracy_score(y_test.argmax(axis=1), y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m load_model\n\u001b[1;32m      3\u001b[0m lstm_model \u001b[39m=\u001b[39m load_model(\u001b[39m\"\u001b[39m\u001b[39mmodel4 3.keras\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm_model = load_model(\"model4 3.keras\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_lstm = lstm_model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(precision_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(accuracy_score(y_test.argmax(axis=1), y_pred_lstm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def get_model():\n",
    "    nclass = 2\n",
    "    inp = tf.keras.layers.Input(shape=(500, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"baseline_cnn.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid),\n",
    "          batch_size=128, epochs=100, callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cnn_model = model\n",
    "\n",
    "pred_test_cnn = cnn_model.predict(X_test)\n",
    "pred_test_cnn = np.argmax(pred_test_cnn, axis=1)\n",
    "\n",
    "print(recall_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(precision_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(accuracy_score(y_test.argmax(axis=1), pred_test_cnn ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import stumpy\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial import distance\n",
    "from fatf.utils.kernels import exponential_kernel \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/rithikbansal/v2.0/listen_to_your_heart/LIMESegment')\n",
    "\n",
    "from Utils.explanations import LIMESegment, NEVES, LEFTIST, NNSegment, RBP, background_perturb\n",
    "from  Utils.data import loadUCRDataID\n",
    "from  Utils.models import *\n",
    "from  Utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "random_test_data_points = {}\n",
    "number_of_test_plots = 2\n",
    "\n",
    "for _ in range(number_of_test_plots):\n",
    "    index = random.randint(0, min(len(y_test_raw),len(X_test)))\n",
    "    cnn_exp = LIMESegment(X_test[index], cnn_model, 'class', 'dtw', 100, 3, 5)\n",
    "\n",
    "    random_test_data_points[index] = [(y_test_raw[index], pred_test_cnn[index]), cnn_exp, 'CNN']\n",
    "\n",
    "\n",
    "labels_for_plots = ['healthy heart', 'heart failure risk']\n",
    "\n",
    "def generic_generate_plots(actual_prediction, model_prediction, model_name, model_exp, all_data):\n",
    "\n",
    "    color_intensity = model_exp[0][int(model_prediction)]\n",
    "    segment_indices = model_exp[1]\n",
    "\n",
    "    normalized_color_intensity = np.zeros_like(color_intensity)\n",
    "\n",
    "    positive_values = color_intensity[color_intensity > 0]\n",
    "    negative_values = color_intensity[color_intensity < 0]\n",
    "\n",
    "    min_positive, max_negative = 0, 0\n",
    "    max_positive = 0\n",
    "    min_negative = None\n",
    "\n",
    "    if len(positive_values) > 0:\n",
    "        min_positive = np.min(positive_values)\n",
    "        max_positive = np.max(positive_values)\n",
    "        scaled_positive = positive_values / max_positive\n",
    "        normalized_color_intensity[color_intensity > 0] = scaled_positive\n",
    "    else:\n",
    "        scaled_positive = np.zeros_like(color_intensity)\n",
    "\n",
    "    if len(negative_values) > 0:\n",
    "        max_negative = np.max(negative_values)\n",
    "        min_negative = np.min(negative_values)\n",
    "        scaled_negative = negative_values / np.abs(min_negative)\n",
    "        normalized_color_intensity[color_intensity < 0] = -scaled_negative\n",
    "    else:\n",
    "        scaled_negative = np.zeros_like(color_intensity)\n",
    "\n",
    "\n",
    "    normalized_color_intensity = [(normalized_color_intensity[l] + 0.00001) if color_intensity[l] > 0 and (normalized_color_intensity[l] < 1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "    normalized_color_intensity = [(normalized_color_intensity[l] - 0.00001) if color_intensity[l] < 0 and (normalized_color_intensity[l] > -1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "\n",
    "    if model_prediction == 0:\n",
    "        cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "                                                            (max_positive, 'green'),(1, 'green')])\n",
    "        cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "                                                            (max_positive, 'red'),(1, 'red')])\n",
    "    else:\n",
    "        cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "                                                            (max_positive, 'green'),(1, 'green')])\n",
    "        cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "                                                            (max_positive, 'red'),(1, 'red')])\n",
    "\n",
    "    segment_collection = []\n",
    "    fig, ax = plt.subplots(figsize=(18,4))\n",
    "    ax.plot(range(len(all_data)), all_data, color='black', label='RR interval data')\n",
    "\n",
    "    for i in range(len(color_intensity)):\n",
    "        start = segment_indices[i]\n",
    "        end = segment_indices[i+1]\n",
    "        intensity = color_intensity[i]\n",
    "        end = end if end >= 0 else len(all_data) - 1\n",
    "\n",
    "        color = None\n",
    "        if color_intensity[i] < 0:\n",
    "            color = cmap_neg(normalized_color_intensity[i])\n",
    "        else:\n",
    "            color = cmap_pos(normalized_color_intensity[i])\n",
    "        \n",
    "        width = end - start\n",
    "\n",
    "        segment = Rectangle((start, ax.get_ylim()[0]), width, ax.get_ylim()[1] - ax.get_ylim()[0], alpha=abs(normalized_color_intensity[i]), color=color, label=f'Segment: {start}-{end}. Intensity: {intensity: .4f}')\n",
    "        segment_collection.append(segment)\n",
    "        ax.add_patch(segment)\n",
    "\n",
    "    ax.autoscale()\n",
    "    ax.set_xlabel('RR interval data points')\n",
    "    ax.set_ylabel('RR Interval Length')\n",
    "    ax.set_title(f'Comparision of {model_name} model. Actual: {labels_for_plots[int(actual_prediction[1])]}, predicted: {labels_for_plots[int(model_prediction)]}')\n",
    "    print(f'Comparision of {model_name} model. Actual: {labels_for_plots[int(actual_prediction[1])]}, predicted: {labels_for_plots[int(model_prediction)]}')\n",
    "\n",
    "    plt.show()\n",
    "    # Uncomment if you want to save the plot\n",
    "    # fig.savefig(f'{model_name}_plot_{ind}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "for ind, data_point in random_test_data_points.items():\n",
    "    actual_prediction = data_point[0][0]\n",
    "    model_prediction = data_point[0][1]\n",
    "    all_data = X_test_raw[ind]\n",
    "    model_exp = data_point[1]\n",
    "    model_name = data_point[2]\n",
    "\n",
    "    generic_generate_plots(actual_prediction, model_prediction, model_name, model_exp, all_data)\n",
    "\n",
    "\n",
    "\n",
    "# def generate_plots(data_point, ind):\n",
    "#     actual_prediction = data_point[0][0]\n",
    "#     cnn_prediction = data_point[0][1]\n",
    "#     lstm_prediction = data_point[0][2]\n",
    "\n",
    "#     print(cnn_prediction, lstm_prediction)\n",
    "\n",
    "#     cnn_exp = data_point[1]\n",
    "#     lstm_exp = data_point[2]\n",
    "    \n",
    "#     all_data = X_test_raw[ind]\n",
    "\n",
    "#     #Plotting CNN data \n",
    "#     color_intensity = cnn_exp[0][int(cnn_prediction)]\n",
    "#     segment_indices = cnn_exp[1]\n",
    "\n",
    "#     normalized_color_intensity = np.zeros_like(color_intensity)\n",
    "\n",
    "#     positive_values = color_intensity[color_intensity > 0]\n",
    "#     negative_values = color_intensity[color_intensity < 0]\n",
    "\n",
    "#     min_positive, max_negative = 0, 0\n",
    "#     max_positive = 0\n",
    "#     min_negative = None\n",
    "\n",
    "#     if len(positive_values) > 0:\n",
    "#         min_positive = np.min(positive_values)\n",
    "#         max_positive = np.max(positive_values)\n",
    "#         scaled_positive = positive_values / max_positive\n",
    "#         normalized_color_intensity[color_intensity > 0] = scaled_positive\n",
    "#     else:\n",
    "#         scaled_positive = np.zeros_like(color_intensity)\n",
    "\n",
    "#     if len(negative_values) > 0:\n",
    "#         max_negative = np.max(negative_values)\n",
    "#         min_negative = np.min(negative_values)\n",
    "#         scaled_negative = negative_values / np.abs(min_negative)\n",
    "#         normalized_color_intensity[color_intensity < 0] = -scaled_negative\n",
    "#     else:\n",
    "#         scaled_negative = np.zeros_like(color_intensity)\n",
    "\n",
    "#     # normalized_color_intensity = np.zeros_like(color_intensity)\n",
    "#     # normalized_color_intensity[color_intensity > 0] = scaled_positive\n",
    "\n",
    "#     normalized_color_intensity = [(normalized_color_intensity[l] + 0.00001) if color_intensity[l] > 0 and (normalized_color_intensity[l] < 1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "#     normalized_color_intensity = [(normalized_color_intensity[l] - 0.00001) if color_intensity[l] < 0 and (normalized_color_intensity[l] > -1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "\n",
    "\n",
    "#     print(normalized_color_intensity)\n",
    "#     print(color_intensity)\n",
    "\n",
    "#     if cnn_prediction == 0:\n",
    "#         cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "#                                                             (max_positive, 'green'),(1, 'green')])\n",
    "#         cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "#                                                             (max_positive, 'red'),(1, 'red')])\n",
    "#     else:\n",
    "#         cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "#                                                             (max_positive, 'green'),(1, 'green')])\n",
    "#         cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "#                                                             (max_positive, 'red'),(1, 'red')])\n",
    "\n",
    "\n",
    "#     segment_collection = []\n",
    "#     fig, ax = plt.subplots(figsize=(18,4))\n",
    "#     ax.plot(range(len(all_data)), all_data, color='black', label='RR interval data')\n",
    "\n",
    "#     for i in range(len(color_intensity)):\n",
    "#         start = segment_indices[i]\n",
    "#         end = segment_indices[i+1]\n",
    "#         intensity = color_intensity[i]\n",
    "#         end = end if end >= 0 else len(all_data) - 1\n",
    "\n",
    "#         color = None\n",
    "#         if color_intensity[i] < 0:\n",
    "#             color = cmap_neg(normalized_color_intensity[i])\n",
    "#         else:\n",
    "#             color = cmap_pos(normalized_color_intensity[i])\n",
    "        \n",
    "#         width = end - start\n",
    "\n",
    "#         segment = Rectangle((start, ax.get_ylim()[0]), width, ax.get_ylim()[1] - ax.get_ylim()[0], alpha=abs(normalized_color_intensity[i]), color=color, label=f'Segment: {start}-{end}. Intensity: {intensity: .4f}')\n",
    "#         segment_collection.append(segment)\n",
    "#         ax.add_patch(segment)\n",
    "\n",
    "#     ax.autoscale()\n",
    "#     ax.set_ylabel('RR Interval Length')\n",
    "#     print(f'Comparision of CNN model. Actual: {labels_for_plots[int(actual_prediction[1])]}, predicted: {labels_for_plots[int(cnn_prediction)]}')\n",
    "\n",
    "#     # plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "#     plt.show()\n",
    "#     fig.savefig(f'CNN_plot_{ind}.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #plotting LSTM model\n",
    "#     color_intensity = lstm_exp[0][int(lstm_prediction)]\n",
    "#     segment_indices = lstm_exp[1]\n",
    "\n",
    "#     normalized_color_intensity = np.zeros_like(color_intensity)\n",
    "\n",
    "#     positive_values = color_intensity[color_intensity > 0]\n",
    "#     negative_values = color_intensity[color_intensity < 0]\n",
    "\n",
    "#     min_positive, max_negative = 0, 0\n",
    "#     max_positive = 0\n",
    "#     min_negative = None\n",
    "\n",
    "#     if len(positive_values) > 0:\n",
    "#         min_positive = np.min(positive_values)\n",
    "#         max_positive = np.max(positive_values)\n",
    "#         scaled_positive = positive_values / max_positive\n",
    "#         normalized_color_intensity[color_intensity > 0] = scaled_positive\n",
    "#     else:\n",
    "#         scaled_positive = np.zeros_like(color_intensity)\n",
    "\n",
    "#     if len(negative_values) > 0:\n",
    "#         max_negative = np.max(negative_values)\n",
    "#         min_negative = np.min(negative_values)\n",
    "#         scaled_negative = negative_values / np.abs(min_negative)\n",
    "#         normalized_color_intensity[color_intensity < 0] = -scaled_negative\n",
    "#     else:\n",
    "#         scaled_negative = np.zeros_like(color_intensity)\n",
    "\n",
    "#     # normalized_color_intensity = np.zeros_like(color_intensity)\n",
    "#     # normalized_color_intensity[color_intensity > 0] = scaled_positive\n",
    "\n",
    "#     normalized_color_intensity = [(normalized_color_intensity[l] + 0.00001) if color_intensity[l] > 0 and (normalized_color_intensity[l] < 1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "#     normalized_color_intensity = [(normalized_color_intensity[l] - 0.00001) if color_intensity[l] < 0 and (normalized_color_intensity[l] > -1) else normalized_color_intensity[l] for l in range(len(color_intensity))]\n",
    "\n",
    "\n",
    "#     print(normalized_color_intensity)\n",
    "#     print(color_intensity)\n",
    "\n",
    "#     if lstm_prediction == 0:\n",
    "#         cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "#                                                             (max_positive, 'green'),(1, 'green')])\n",
    "#         cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "#                                                             (max_positive, 'red'),(1, 'red')])\n",
    "#     else:\n",
    "#         cmap_neg = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'green'), (min_positive, 'green'),\n",
    "#                                                             (max_positive, 'green'),(1, 'green')])\n",
    "#         cmap_pos = LinearSegmentedColormap.from_list('custom_colormap', [(0, 'red'), (min_positive, 'red'),\n",
    "#                                                             (max_positive, 'red'),(1, 'red')])\n",
    "\n",
    "\n",
    "#     segment_collection = []\n",
    "#     fig, ax = plt.subplots(figsize=(18,4))\n",
    "#     ax.plot(range(len(all_data)), all_data, color='black', label='RR interval data')\n",
    "\n",
    "#     for i in range(len(color_intensity)):\n",
    "#         start = segment_indices[i]\n",
    "#         end = segment_indices[i+1]\n",
    "#         intensity = color_intensity[i]\n",
    "#         end = end if end >= 0 else len(all_data) - 1\n",
    "\n",
    "#         color = None\n",
    "#         if color_intensity[i] < 0:\n",
    "#             color = cmap_neg(normalized_color_intensity[i])\n",
    "#         else:\n",
    "#             color = cmap_pos(normalized_color_intensity[i])\n",
    "        \n",
    "#         width = end - start\n",
    "\n",
    "#         segment = Rectangle((start, ax.get_ylim()[0]), width, ax.get_ylim()[1] - ax.get_ylim()[0], alpha=abs(normalized_color_intensity[i]), color=color, label=f'Segment: {start}-{end}. Intensity: {intensity: .4f}')\n",
    "#         segment_collection.append(segment)\n",
    "#         ax.add_patch(segment)\n",
    "\n",
    "#     ax.autoscale()\n",
    "#     ax.set_xlabel('RR Interval')\n",
    "#     ax.set_ylabel('RR Interval Length')\n",
    "#     print(f'Comparision of LSTM model. Actual: {labels_for_plots[int(actual_prediction[1])]}, predicted: {labels_for_plots[int(cnn_prediction)]}')\n",
    "\n",
    "#     plt.show()\n",
    "#     fig.savefig(f'LSTM_plot_{ind}.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# for ind, data_point in random_test_data_points.items():\n",
    "#     # print(ind)\n",
    "#     generate_plots(data_point, ind)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        print(i)\n",
    "        count+=1\n",
    "print(\"count mismatches\", count)\n",
    "print(\"Total samples \", len(y_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != y_test[i][1]:\n",
    "        count+=1\n",
    "print(\"count lstm is wrong\", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if pred_test_cnn[i] != y_test[i][1]:\n",
    "        count+=1\n",
    "print(\"count cnn is wrong\", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        if y_pred_lstm[i] != y_test[i][1]:\n",
    "            count+=1\n",
    "print(\"count lstm is wrong in mismatched data \", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        if pred_test_cnn[i] != y_test[i][1]:\n",
    "            count+=1\n",
    "print(\"count cnn is wrong in mismatched data \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 91\n",
    "print(\"Actual, CNN, LSTM\")\n",
    "print(y_test[index], pred_test_cnn[index], y_pred_lstm[index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match: \n",
    "\n",
    "1: 28,-1 (same f, cnn>>lstm), 7,46 (same f, lstm>cnn), \n",
    "\n",
    "0: 6 (same f, lstm>>cnn)\n",
    "\n",
    "\n",
    "mismatch:\n",
    "\n",
    "21, 70, 112, 126 (Exact same f, opp pred) lstm got it right\n",
    "\n",
    "62, 112 (lstm v conf, cnn not conf at all)\n",
    "\n",
    "91, 126 (cnn conf, lstm not conf at all)\n",
    "\n",
    "62, 91 lstm wrong "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
