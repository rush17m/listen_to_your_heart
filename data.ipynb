{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "seg_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7397, 500), (7397, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = None\n",
    "# y = None\n",
    "\n",
    "# for db in [\"chf2db\", \"chfdb\"]:\n",
    "#     for record in os.listdir(f'data/{db}/rr'):\n",
    "#         rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "#         n_segments = rr.shape[0] // seg_length\n",
    "#         rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "#         labels = np.c_[np.ones(n_segments), np.zeros(n_segments)]\n",
    "\n",
    "#         if x is None or y is None:\n",
    "#             x = rr\n",
    "#             y = labels\n",
    "#         else:\n",
    "#             x = np.r_[rr, x]\n",
    "#             y = np.r_[labels, y]\n",
    "\n",
    "\n",
    "# for db in [\"nsrdb\", \"nsr2db\", \"fantasia\"]:\n",
    "#     for record in os.listdir(f'data/{db}/rr'):\n",
    "#         rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "#         n_segments = rr.shape[0] // seg_length\n",
    "#         rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "#         labels = np.c_[np.zeros(n_segments), np.ones(n_segments)]\n",
    "\n",
    "#         if x is None or y is None:\n",
    "#             x = rr\n",
    "#             y = labels\n",
    "#         else:\n",
    "#             x = np.r_[rr, x]\n",
    "#             y = np.r_[labels, y]\n",
    "\n",
    "# x.shape, y.shape\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "db1_pos = ['chfdb']\n",
    "db1_neg = ['nsrdb', 'fantasia']\n",
    "db2_pos = ['chf2db']\n",
    "db2_neg = ['nsr2db']\n",
    "\n",
    "for db in db1_pos:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.ones(n_segments), np.zeros(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "for db in db1_neg:\n",
    "    for record in os.listdir(f'data/{db}/rr'):\n",
    "        rr = np.loadtxt(f'data/{db}/rr/{record}')\n",
    "        n_segments = rr.shape[0] // seg_length\n",
    "        rr = rr[:n_segments*seg_length].reshape((n_segments, seg_length))\n",
    "        labels = np.c_[np.zeros(n_segments), np.ones(n_segments)]\n",
    "\n",
    "        if X is None or y is None:\n",
    "            X = rr\n",
    "            y = labels\n",
    "        else:\n",
    "            X = np.r_[rr, X]\n",
    "            y = np.r_[labels, y]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5991, 500), (666, 500), (740, 500))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# x = preprocessing.scale(x, axis=1)\n",
    "# # scaler = preprocessing.StandardScaler().fit_transform(x)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=410)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=410)\n",
    "\n",
    "# X_train.shape, X_valid.shape, X_test.shape\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = preprocessing.scale(X, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=410)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=410)\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([12796,  7996], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train[:,0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 500, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 500, 10)      280         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 500, 5)       10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 5)       10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 166, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500, 5)       320         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 498, 5)       80          conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 496, 5)       130         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 166, 5)       10          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1660, 5)      0           lstm_1[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1660, 10)     440         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1660, 5)      30          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1660, 5)      30          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 553, 5)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 1660, 5)      320         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1658, 5)      80          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1656, 5)      130         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 553, 5)       30          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5527, 5)      0           lstm_3[0][0]                     \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 5527, 5)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 27635)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            55272       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,172\n",
      "Trainable params: 57,172\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(500, 1))\n",
    "\n",
    "def inception_lstm(inputs):\n",
    "    a = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(5, return_sequences=True))(inputs)\n",
    "    a = tf.keras.layers.LSTM(5, return_sequences=True)(a)\n",
    "\n",
    "    b = tf.keras.layers.Conv1D(5, kernel_size=1)(inputs)\n",
    "    b = tf.keras.layers.Conv1D(5, kernel_size=3)(b)\n",
    "\n",
    "    c = tf.keras.layers.Conv1D(5, kernel_size=1)(inputs)\n",
    "    c = tf.keras.layers.Conv1D(5, kernel_size=5)(c)\n",
    "\n",
    "    d = tf.keras.layers.MaxPool1D(3)(inputs)\n",
    "    d = tf.keras.layers.Conv1D(5, kernel_size=1)(d)\n",
    "\n",
    "    concat = tf.keras.layers.Concatenate(1)([a, b, c, d])\n",
    "    return concat\n",
    "\n",
    "layer1 = inception_lstm(inputs)\n",
    "layer2 = inception_lstm(layer1)\n",
    "dropout = tf.keras.layers.Dropout(0.2)(layer2)\n",
    "flattened = tf.keras.layers.Flatten()(dropout)\n",
    "output = tf.keras.layers.Dense(2, activation='sigmoid')(flattened)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 126s 771ms/step - loss: 0.5902 - accuracy: 0.6903 - val_loss: 0.6900 - val_accuracy: 0.6694\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 126s 774ms/step - loss: 0.5874 - accuracy: 0.6944 - val_loss: 0.6617 - val_accuracy: 0.6720\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 128s 784ms/step - loss: 0.5836 - accuracy: 0.6949 - val_loss: 0.6417 - val_accuracy: 0.6716\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 129s 791ms/step - loss: 0.5826 - accuracy: 0.6971 - val_loss: 0.6472 - val_accuracy: 0.6612\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 158s 968ms/step - loss: 0.5851 - accuracy: 0.6943 - val_loss: 0.6581 - val_accuracy: 0.6811\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 154s 946ms/step - loss: 0.5813 - accuracy: 0.6955 - val_loss: 0.6796 - val_accuracy: 0.6724\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 154s 944ms/step - loss: 0.5846 - accuracy: 0.6966 - val_loss: 0.6677 - val_accuracy: 0.6750\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 156s 959ms/step - loss: 0.5799 - accuracy: 0.6971 - val_loss: 0.6658 - val_accuracy: 0.6586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fdde9074c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid),\n",
    "          batch_size=128, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_lstm.keras')\n",
    "lstm_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_lstm = lstm_model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892764857881137\n",
      "0.7283276450511945\n",
      "0.6575769380599922\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(precision_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(accuracy_score(y_test.argmax(axis=1), y_pred_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lstm_model = load_model(\"model4 3.keras\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 500, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 500, 10)      280         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 500, 5)       10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 5)       10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 166, 1)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500, 5)       320         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 5)       80          conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 5)       130         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 166, 5)       10          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1666, 5)      0           lstm_1[0][0]                     \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 1666, 10)     440         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1666, 5)      30          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1666, 5)      30          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 555, 5)       0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 1666, 5)      320         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1666, 5)      80          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1666, 5)      130         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 555, 5)       30          max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5553, 5)      0           lstm_3[0][0]                     \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 5553, 5)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 27765)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            55532       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,432\n",
      "Trainable params: 57,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred_lstm = lstm_model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9836065573770492\n",
      "0.9813084112149533\n",
      "0.9797297297297297\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(precision_score(y_test.argmax(axis=1), y_pred_lstm))\n",
    "print(accuracy_score(y_test.argmax(axis=1), y_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 500, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 496, 16)           96        \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 492, 16)           1296      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 246, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 246, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 244, 32)           1568      \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 242, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 119, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 117, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 58, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 58, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 56, 256)           24832     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 54, 256)           196864    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 254,706\n",
      "Trainable params: 254,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 6s 105ms/step - loss: 0.4785 - acc: 0.7678 - val_loss: 0.4053 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.85586, saving model to baseline_cnn.h5\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 4s 94ms/step - loss: 0.3184 - acc: 0.8790 - val_loss: 0.3208 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.85586 to 0.89489, saving model to baseline_cnn.h5\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.2799 - acc: 0.8977 - val_loss: 0.3172 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89489\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.2522 - acc: 0.9089 - val_loss: 0.2621 - val_acc: 0.9024\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89489 to 0.90240, saving model to baseline_cnn.h5\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.2242 - acc: 0.9195 - val_loss: 0.2448 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90240 to 0.90390, saving model to baseline_cnn.h5\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.2059 - acc: 0.9271 - val_loss: 0.2432 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90390 to 0.91141, saving model to baseline_cnn.h5\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 0.1937 - acc: 0.9266 - val_loss: 0.2342 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91141\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.1772 - acc: 0.9329 - val_loss: 0.2550 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91141\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1938 - acc: 0.9254 - val_loss: 0.2365 - val_acc: 0.9159\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.91141 to 0.91592, saving model to baseline_cnn.h5\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.1682 - acc: 0.9399 - val_loss: 0.1792 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91592 to 0.92192, saving model to baseline_cnn.h5\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 4s 92ms/step - loss: 0.1664 - acc: 0.9369 - val_loss: 0.2894 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92192\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.1851 - acc: 0.9324 - val_loss: 0.1881 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92192 to 0.92643, saving model to baseline_cnn.h5\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1515 - acc: 0.9427 - val_loss: 0.2104 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.92643\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.1348 - acc: 0.9473 - val_loss: 0.1824 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.92643 to 0.92793, saving model to baseline_cnn.h5\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 4s 93ms/step - loss: 0.1341 - acc: 0.9486 - val_loss: 0.1626 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92793 to 0.93243, saving model to baseline_cnn.h5\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.1409 - acc: 0.9468 - val_loss: 0.1672 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.93243 to 0.93393, saving model to baseline_cnn.h5\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1329 - acc: 0.9506 - val_loss: 0.1849 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93393\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1249 - acc: 0.9539 - val_loss: 0.1578 - val_acc: 0.9324\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93393\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.1203 - acc: 0.9548 - val_loss: 0.1723 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93393\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.1036 - acc: 0.9609 - val_loss: 0.1519 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.93393 to 0.93994, saving model to baseline_cnn.h5\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 4s 89ms/step - loss: 0.0968 - acc: 0.9619 - val_loss: 0.1570 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.93994\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 4s 96ms/step - loss: 0.1018 - acc: 0.9629 - val_loss: 0.1532 - val_acc: 0.9384\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.93994\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 4s 90ms/step - loss: 0.0989 - acc: 0.9623 - val_loss: 0.1553 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.93994\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 4s 91ms/step - loss: 0.0972 - acc: 0.9629 - val_loss: 0.1545 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.93994\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 4s 88ms/step - loss: 0.0906 - acc: 0.9649 - val_loss: 0.1544 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.93994\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def get_model():\n",
    "    nclass = 2\n",
    "    inp = tf.keras.layers.Input(shape=(500, 1))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = Dropout(rate=0.1)(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = GlobalMaxPool1D()(img_1)\n",
    "    img_1 = Dropout(rate=0.2)(img_1)\n",
    "\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
    "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
    "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3\")(dense_1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=dense_1)\n",
    "    opt = tf.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['acc'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "file_path = \"baseline_cnn.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "model.fit(x=X_train, y=y_train, validation_data=(X_valid, y_valid),\n",
    "          batch_size=128, epochs=100, callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9508196721311475\n",
      "0.9441860465116279\n",
      "0.9391891891891891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cnn_model = model\n",
    "\n",
    "pred_test_cnn = cnn_model.predict(X_test)\n",
    "pred_test_cnn = np.argmax(pred_test_cnn, axis=1)\n",
    "\n",
    "print(recall_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(precision_score(y_test.argmax(axis=1), pred_test_cnn ))\n",
    "print(accuracy_score(y_test.argmax(axis=1), pred_test_cnn ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import stumpy\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.spatial import distance\n",
    "from fatf.utils.kernels import exponential_kernel \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Rushali\\\\Documents\\\\Code\\\\AI project\\\\listen_to_your_heart\\\\LIMESegment')\n",
    "\n",
    "from Utils.explanations import LIMESegment, NEVES, LEFTIST, NNSegment, RBP, background_perturb\n",
    "from  Utils.data import loadUCRDataID\n",
    "from  Utils.models import *\n",
    "from  Utils.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0133, -0.0345,  0.0102, -0.0277, -0.0131,  0.0302,  0.0087,\n",
       "        0.0123,  0.0458,  0.0098,  0.0664, -0.0279,  0.0394,  0.0538,\n",
       "        0.0469,  0.0087,  0.0517, -0.0173,  0.0168,  0.024 ,  0.0232,\n",
       "        0.0436, -0.072 ,  0.0062, -0.0124, -0.0131, -0.0409,  0.0249,\n",
       "       -0.0082,  0.0213,  0.0124,  0.0029,  0.0051, -0.0032,  0.0106,\n",
       "       -0.0224,  0.0305,  0.0041,  0.0191, -0.0325, -0.0066,  0.0095,\n",
       "       -0.0291, -0.0111,  0.0143,  0.0364,  0.0211,  0.0189,  0.0142,\n",
       "        0.571 , -0.0226])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_exp = LIMESegment(X_test[-2], cnn_model, 'class', 'dtw', 100, 3, 50)\n",
    "cnn_exp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1946, -0.0166,  0.0066, -0.0037, -0.0002,  0.0134,  0.0068,\n",
       "        0.0151, -0.007 , -0.0067,  0.002 , -0.0133,  0.0036, -0.0152,\n",
       "        0.0044, -0.0018, -0.0025, -0.002 , -0.0106, -0.0028,  0.0195,\n",
       "       -0.012 , -0.0042, -0.0049,  0.0038, -0.0007,  0.0163, -0.0063,\n",
       "       -0.0185, -0.0187,  0.0011, -0.0081, -0.0142,  0.0136, -0.0052,\n",
       "       -0.0119,  0.002 ,  0.0044,  0.0005,  0.0217,  0.0139,  0.0047,\n",
       "       -0.0042, -0.0006, -0.0127,  0.0016,  0.0025,  0.0111,  0.0112,\n",
       "        0.2184, -0.0113])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_exp = LIMESegment(X_test[6], lstm_model, 'class', 'dtw', 100, 3, 50)\n",
    "lstm_exp[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual, CNN, LSTM\n",
      "[1. 0.] 1 0\n",
      "\n",
      "CNN\n",
      "(array([[ 0.1702,  0.009 ,  0.01  ,  0.0046, -0.1612, -0.0175],\n",
      "       [-0.1647, -0.0087, -0.0091, -0.0042,  0.1695,  0.0167]]), [0, 159, 160, 162, 174, 496, -1])\n",
      "\n",
      "LSTM\n",
      "(array([[-4.2554e-04,  3.0783e-03,  1.1406e-02, -1.8721e-03,  8.4891e-01,\n",
      "         1.7612e-02],\n",
      "       [-9.1165e-04, -3.3329e-03, -1.1539e-02,  1.4135e-03, -8.4688e-01,\n",
      "        -1.7548e-02]]), [0, 159, 160, 162, 174, 496, -1])\n"
     ]
    }
   ],
   "source": [
    "index = 112\n",
    "print(\"Actual, CNN, LSTM\")\n",
    "print(y_test[index], pred_test_cnn[index], y_pred_lstm[index])\n",
    "cnn_exp = LIMESegment(X_test[index], cnn_model, 'class', 'dtw', 100, 3, 5)\n",
    "lstm_exp = LIMESegment(X_test[index], lstm_model, 'class', 'dtw', 100, 3, 5)\n",
    "print(\"\\nCNN\")\n",
    "print(cnn_exp)\n",
    "print(\"\\nLSTM\")\n",
    "print(lstm_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "62\n",
      "70\n",
      "91\n",
      "112\n",
      "126\n",
      "152\n",
      "164\n",
      "165\n",
      "180\n",
      "192\n",
      "198\n",
      "254\n",
      "258\n",
      "262\n",
      "311\n",
      "315\n",
      "321\n",
      "322\n",
      "333\n",
      "366\n",
      "372\n",
      "383\n",
      "406\n",
      "407\n",
      "408\n",
      "412\n",
      "415\n",
      "467\n",
      "518\n",
      "521\n",
      "544\n",
      "560\n",
      "591\n",
      "599\n",
      "623\n",
      "634\n",
      "687\n",
      "699\n",
      "708\n",
      "732\n",
      "736\n",
      "count mismatches 42\n",
      "Total samples  740\n",
      "count lstm is wrong 15\n",
      "count cnn is wrong 45\n",
      "count lstm is wrong in mismatched data  6\n",
      "count cnn is wrong in mismatched data  36\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        print(i)\n",
    "        count+=1\n",
    "print(\"count mismatches\", count)\n",
    "print(\"Total samples \", len(y_test))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != y_test[i][1]:\n",
    "        count+=1\n",
    "print(\"count lstm is wrong\", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if pred_test_cnn[i] != y_test[i][1]:\n",
    "        count+=1\n",
    "print(\"count cnn is wrong\", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        if y_pred_lstm[i] != y_test[i][1]:\n",
    "            count+=1\n",
    "print(\"count lstm is wrong in mismatched data \", count)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred_lstm[i] != pred_test_cnn[i]:\n",
    "        if pred_test_cnn[i] != y_test[i][1]:\n",
    "            count+=1\n",
    "print(\"count cnn is wrong in mismatched data \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual, CNN, LSTM\n",
      "[1. 0.] 0 1\n"
     ]
    }
   ],
   "source": [
    "index = 91\n",
    "print(\"Actual, CNN, LSTM\")\n",
    "print(y_test[index], pred_test_cnn[index], y_pred_lstm[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match: \n",
    "1: 28,-1 (same f, cnn>>lstm), 7,46 (same f, lstm>cnn), \n",
    "0: 6 (same f, lstm>>cnn)\n",
    "\n",
    "mismatch:\n",
    "21, 70, 112, 126 (Exact same f, opp pred) lstm got it right\n",
    "62, 112 (lstm v conf, cnn not conf at all)\n",
    "91, 126 (cnn conf, lstm not conf at all)\n",
    "\n",
    "62, 91 lstm wrong "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
